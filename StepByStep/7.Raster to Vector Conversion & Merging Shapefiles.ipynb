{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Special libraries required\n",
    "import pyproj    \n",
    "import shapely\n",
    "import shapely.ops as ops\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Define Button\n",
    "def convert(shp):\n",
    "    '''\n",
    "    When we export the TIF file from GEE, the file that contains all the loss data, the resulting raster will have multiple bands \n",
    "    each representing different annaul loss. Before we calculate the distance between seagrass & possible erosion places we need to \n",
    "    - Export each TIF band to seperate shapefiles\n",
    "    - Select attribute for loss polygons (0=no change 1=loss). We only need 1=loss\n",
    "    - Merge all these polygons. Now we have a single merge.shp file that represents the cumulative (total) erosion areas for all years\n",
    "    - Import this merge file & your seagrass file (must be named Seagrass.shp , case sensetive)\n",
    "    - Project these files\n",
    "    - Find centroid of polygons\n",
    "    - Calculate nearest distance between seagrass centroids to erosion centroids\n",
    "    - Edit dataframe & save risk index shape file\n",
    "    - Map it\n",
    "    '''\n",
    "    \n",
    "    ######################## LOSS TIFF ########################\n",
    "\n",
    "    ######################## 1: Open TIF file\n",
    "    raster_path = os.path.join(os.path.expanduser('~'), 'Downloads/Seagrass_Vulnerability_Index/Output/TIF/Total_Max_Loss.tif') \n",
    "    raster = gdal.Open(raster_path) # There are as many bands as change images \n",
    "    band_count = raster.RasterCount\n",
    "    \n",
    "    ######################## 2: Create Folder To Save Shapefiles\n",
    "    \n",
    "    out_dir = os.path.join(os.path.expanduser('~'), 'Downloads/Seagrass_Vulnerability_Index/Output/Loss_Shapefiles')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    ######################## 3: Loop thorugh all the bands in the raster. Each bad represent annual loss amount.\n",
    "    for i in range (band_count+1): \n",
    "    \n",
    "        band = raster.GetRasterBand(i) \n",
    "        \n",
    "        ######################## 4: Convert raster (tif) to vector (shp)\n",
    "        # Convert to shapefile\n",
    "        drv = ogr.GetDriverByName('ESRI Shapefile')\n",
    "        outfile_path = os.path.join(out_dir, 'Loss_Polygon{}.shp'.format(i))\n",
    "        outfile = drv.CreateDataSource(outfile_path) \n",
    "        outlayer = outfile.CreateLayer('polygonized raster', srs = None )\n",
    "        newField = ogr.FieldDefn('Value', ogr.OFTReal)\n",
    "        outlayer.CreateField(newField)\n",
    "        \n",
    "        #from contextlib import suppress #This helps ignoring execptions \n",
    "        with suppress(Exception):\n",
    "            gdal.Polygonize(band, None, outlayer, 0, []) \n",
    "            outfile = None\n",
    "    \n",
    "    ######################## 5: Remove the first shapefile (shp, dbf and shx) gdal creates an empty file (why?)\n",
    "    shapefile0 = os.path.join(out_dir, 'Loss_Polygon0.shp')\n",
    "    shapefile0dbf = os.path.join(out_dir, 'Loss_Polygon0.dbf')\n",
    "    shapefile0shx = os.path.join(out_dir, 'Loss_Polygon0.shx')\n",
    "\n",
    "    ## delete only if file exists ##\n",
    "    if os.path.exists(shapefile0):\n",
    "        os.remove(shapefile0)\n",
    "        os.remove(shapefile0dbf)\n",
    "        os.remove(shapefile0shx)\n",
    "    else:\n",
    "        print(\"Sorry, I can not remove %s file.\" % shapefile0)\n",
    "    \n",
    "      \n",
    "    ######################## SHAPEFILES ########################\n",
    "    \n",
    "    ######################## 7: Select by Attribute & Merge Shapefiles\n",
    "    \n",
    "\n",
    "    # Link http://pcjericks.github.io/py-gdalogr-cookbook/vector_layers.html#merge-ogr-layers\n",
    "    outputMergefn = os.path.join(out_dir, 'Merge.shp') # Output directory and file name\n",
    "    fileStartsWith = 'Loss_Polygon'\n",
    "    fileEndsWith = '.shp'\n",
    "    driverName = 'ESRI Shapefile'\n",
    "    geometryType = ogr.wkbPolygon\n",
    "\n",
    "    out_driver = ogr.GetDriverByName( driverName )\n",
    "    if os.path.exists(outputMergefn):\n",
    "        out_driver.DeleteDataSource(outputMergefn)\n",
    "    out_ds = out_driver.CreateDataSource(outputMergefn)\n",
    "    out_layer = out_ds.CreateLayer(outputMergefn, geom_type=geometryType)\n",
    "\n",
    "    fileList = os.listdir(out_dir) # The file list is specified above\n",
    "\n",
    "    for file in fileList:\n",
    "        if file.endswith(\".shp\"):\n",
    "            shp_path = os.path.join(out_dir, file)\n",
    "            ds = ogr.Open(shp_path) #ds = datasource\n",
    "            lyr = ds.GetLayer() # lyr = layer\n",
    "            lyr.SetAttributeFilter(\"Value = '1'\") #Select the polygons where value=1 (loss)\n",
    "            for feat in lyr:\n",
    "                out_feat = ogr.Feature(out_layer.GetLayerDefn())\n",
    "                out_feat.SetGeometry(feat.GetGeometryRef().Clone())\n",
    "                out_layer.CreateFeature(out_feat)\n",
    "                out_feat = None\n",
    "                out_layer.SyncToDisk()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
